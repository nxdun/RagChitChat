{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "078e38d4",
   "metadata": {},
   "source": [
    "# CTSE RAG Chatbot\n",
    "This notebook implements the Retrieval-Augmented Generation (RAG) chatbot for CTSE lecture notes. The implementation will be built layer by layer, starting with imports and the document processor.overall design follows OOP Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e720ec",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries\n",
    "We start by importing all the necessary libraries for the RAG chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "60ad5027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, Callable\n",
    "import requests\n",
    "\n",
    "# Document processing libraries\n",
    "import pypdf\n",
    "from pptx import Presentation\n",
    "\n",
    "# Vector database and embedding libraries\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "# Haystack libraries for retrieval\n",
    "from haystack.components.retrievers import InMemoryBM25Retriever\n",
    "from haystack.dataclasses import Document\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "\n",
    "# Terminal UI libraries\n",
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "from rich.panel import Panel\n",
    "from rich.prompt import Prompt, Confirm\n",
    "from rich.table import Table\n",
    "from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn\n",
    "from rich.layout import Layout\n",
    "from rich.live import Live\n",
    "from rich.align import Align\n",
    "from rich.rule import Rule\n",
    "from rich.syntax import Syntax\n",
    "from rich import box, print\n",
    "\n",
    "# Data processing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Environment variable management\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bac0b2d",
   "metadata": {},
   "source": [
    "## Step 2: Core Configuration and Settings\n",
    "This step defines the configuration settings for the chatbot, including constants, environment variables, and reusable templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "12ff073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable Haystack telemetry\n",
    "os.environ['HAYSTACK_TELEMETRY_ENABLED'] = 'False'\n",
    "\n",
    "# Paths configuration\n",
    "DATA_DIR = os.environ.get('RAGCHITCHAT_DATA_DIR', 'data') #im using path in root dir\n",
    "PROCESSED_DIR = os.environ.get('RAGCHITCHAT_PROCESSED_DIR', 'processed')\n",
    "DB_DIR = os.environ.get('RAGCHITCHAT_DB_DIR', 'chroma_db')\n",
    "\n",
    "# Ollama configuration\n",
    "OLLAMA_URL = os.environ.get('OLLAMA_URL', 'http://localhost:11434')\n",
    "DEFAULT_MODEL = os.environ.get('RAGCHITCHAT_MODEL', 'mistral:7b-instruct-v0.3-q4_1')\n",
    "\n",
    "# Document processing\n",
    "CHUNK_SIZE = int(os.environ.get('RAGCHITCHAT_CHUNK_SIZE', '1000'))\n",
    "CHUNK_OVERLAP = int(os.environ.get('RAGCHITCHAT_CHUNK_OVERLAP', '200'))\n",
    "\n",
    "# Retrieval configuration\n",
    "TOP_K_RESULTS = int(os.environ.get('RAGCHITCHAT_TOP_K', '5'))\n",
    "\n",
    "# UI Configuration\n",
    "HISTORY_CAPACITY = int(os.environ.get('RAGCHITCHAT_HISTORY_CAPACITY', '10'))\n",
    "\n",
    "# Advanced System prompt for Ollama with enhanced instructions\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are 'CTSE Scholar', an educational assistant specialized in Current Trends in Software Engineering (CTSE).\n",
    "You have been carefully trained on university-level lecture notes from the CTSE course.\n",
    "\n",
    "YOUR CAPABILITIES:\n",
    "- Explain complex software engineering concepts with academic precision\n",
    "- Provide examples relevant to modern software development practices\n",
    "- Connect theoretical concepts to practical applications in the industry\n",
    "- Analyze the evolution and future directions of software engineering methodologies\n",
    "\n",
    "YOUR LIMITATIONS:\n",
    "- You only possess knowledge contained in the CTSE lecture notes\n",
    "- You cannot access real-time information beyond your training data\n",
    "- You should acknowledge when information is not available in your knowledge base\n",
    "\n",
    "RESPONSE GUIDELINES:\n",
    "- Begin with a direct, concise answer to the question\n",
    "- Structure longer responses with appropriate headings and bullet points\n",
    "- Use academic terminology while remaining accessible to students\n",
    "- Cite specific lectures or sections when possible (e.g., \"According to Lecture 3 on DevOps...\")\n",
    "- When answering coding questions, ensure proper formatting and comments\n",
    "- Include relevant examples to illustrate concepts\n",
    "- For complex topics, break down explanations into sequential logical steps\n",
    "\n",
    "If you don't have enough information to provide a complete answer, clearly acknowledge this limitation and suggest related topics you can address instead.\n",
    "\"\"\"\n",
    "\n",
    "# Advanced RAG prompt template with chain-of-thought reasoning\n",
    "RAG_PROMPT_TEMPLATE = \"\"\"\n",
    "You are a university-level educational assistant specialized in Current Trends in Software Engineering.\n",
    "You will receive context information extracted from CTSE lecture notes and a question from a student.\n",
    "\n",
    "CONTEXT INFORMATION:\n",
    "{context}\n",
    "\n",
    "USER QUESTION:\n",
    "{question}\n",
    "\n",
    "To answer effectively:\n",
    "1. First, carefully analyze what the question is asking.\n",
    "2. Identify which parts of the context are most relevant to the question.\n",
    "3. Think step-by-step about how these concepts should be explained.\n",
    "4. Consider any potential misconceptions the student might have.\n",
    "5. Formulate a clear, structured response that directly addresses the question.\n",
    "\n",
    "Your answer should:\n",
    "- Start with a direct response to the question\n",
    "- Use academic language appropriate for university-level education\n",
    "- Include specific examples when helpful\n",
    "- Use markdown formatting for clarity (headings, bullet points, code blocks)\n",
    "- Cite specific lecture content when possible\n",
    "- Be factually accurate based only on the provided context\n",
    "\n",
    "If the provided context doesn't contain sufficient information to answer the question completely:\n",
    "1. Clearly state what information is not available in your knowledge base\n",
    "2. Provide what partial information you can based on the available context\n",
    "3. Suggest related topics you can address based on the available lecture notes\n",
    "\n",
    "Response format:\n",
    "---\n",
    "## [Direct Answer to Question]\n",
    "[Detailed explanation with structured formatting]\n",
    "\n",
    "[Examples or elaboration as needed]\n",
    "\n",
    "[If applicable: \"Note: The lecture notes do not provide complete information about X, but I can tell you that...\"]\n",
    "---\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40132963",
   "metadata": {},
   "source": [
    "## Step 3: Document Processing Layer\n",
    "This step implements the `DocumentProcessor` base class and its subclasses (`PDFProcessor`, `PPTXProcessor`) for handling lecture notes in PDF and PPTX formats. It also includes the `DocumentProcessorFactory` for selecting the appropriate processor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2eca99de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Processing Layer\n",
    "from abc import ABC, abstractmethod\n",
    "class DocumentProcessor(ABC):\n",
    "    \"\"\"Base class for document processors\"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def process(self, file_path: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Process a document and return chunks of text with metadata\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def save_chunks(self, chunks: List[Dict[str, Any]], output_dir: str, filename: str) -> None:\n",
    "        \"\"\"Save processed chunks to a text file\"\"\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        \n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            for chunk in chunks:\n",
    "                f.write(f\"--- Chunk from {chunk['metadata']['source']} (Page/Slide {chunk['metadata'].get('page_num', 'N/A')}) ---\\n\")\n",
    "                f.write(chunk['content'])\n",
    "                f.write(\"\\n\\n\")\n",
    "        \n",
    "        logger.info(f\"Saved processed content to {output_path}\")\n",
    "\n",
    "class PDFProcessor(DocumentProcessor):\n",
    "    \"\"\"Processor for PDF documents\"\"\"\n",
    "    \n",
    "    def __init__(self, chunk_size: int = 1000, chunk_overlap: int = 200):\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "    \n",
    "    def process(self, file_path: str) -> List[Dict[str, Any]]:\n",
    "        logger.info(f\"Processing PDF: {file_path}\")\n",
    "        chunks = []\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, 'rb') as file:\n",
    "                pdf = pypdf.PdfReader(file)\n",
    "                \n",
    "                for i, page in enumerate(pdf.pages):\n",
    "                    text = page.extract_text()\n",
    "                    if text.strip():\n",
    "                        if len(text) <= self.chunk_size:\n",
    "                            chunks.append({\n",
    "                                'content': text,\n",
    "                                'metadata': {\n",
    "                                    'source': os.path.basename(file_path),\n",
    "                                    'page_num': i + 1\n",
    "                                }\n",
    "                            })\n",
    "                        else:\n",
    "                            start = 0\n",
    "                            while start < len(text):\n",
    "                                end = min(start + self.chunk_size, len(text))\n",
    "                                chunk_text = text[start:end]\n",
    "                                chunks.append({\n",
    "                                    'content': chunk_text,\n",
    "                                    'metadata': {\n",
    "                                        'source': os.path.basename(file_path),\n",
    "                                        'page_num': i + 1,\n",
    "                                        'chunk_part': f\"{start}-{end}\"\n",
    "                                    }\n",
    "                                })\n",
    "                                start += self.chunk_size - self.chunk_overlap\n",
    "                                if start >= len(text):\n",
    "                                    break\n",
    "            \n",
    "            logger.info(f\"Extracted {len(chunks)} chunks from {file_path}\")\n",
    "            return chunks\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing PDF {file_path}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "class PPTXProcessor(DocumentProcessor):\n",
    "    \"\"\"Processor for PowerPoint documents\"\"\"\n",
    "    \n",
    "    def process(self, file_path: str) -> List[Dict[str, Any]]:\n",
    "        logger.info(f\"Processing PPTX: {file_path}\")\n",
    "        chunks = []\n",
    "        \n",
    "        try:\n",
    "            prs = Presentation(file_path)\n",
    "            \n",
    "            for i, slide in enumerate(prs.slides):\n",
    "                slide_text = []\n",
    "                \n",
    "                for shape in slide.shapes:\n",
    "                    if hasattr(shape, \"text\"):\n",
    "                        text = shape.text.strip()\n",
    "                        if text:\n",
    "                            slide_text.append(text)\n",
    "                \n",
    "                if slide_text:\n",
    "                    chunks.append({\n",
    "                        'content': '\\n'.join(slide_text),\n",
    "                        'metadata': {\n",
    "                            'source': os.path.basename(file_path),\n",
    "                            'page_num': i + 1\n",
    "                        }\n",
    "                    })\n",
    "            \n",
    "            logger.info(f\"Extracted {len(chunks)} chunks from {file_path}\")\n",
    "            return chunks\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing PPTX {file_path}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "class DocumentProcessorFactory:\n",
    "    \"\"\"Factory for creating document processors based on file extension\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_processor(file_path: str) -> Optional[DocumentProcessor]:\n",
    "        \"\"\"Get appropriate document processor based on file extension\"\"\"\n",
    "        ext = Path(file_path).suffix.lower()\n",
    "        \n",
    "        if ext == '.pdf':\n",
    "            return PDFProcessor()\n",
    "        elif ext == '.pptx':\n",
    "            return PPTXProcessor()\n",
    "        else:\n",
    "            logger.warning(f\"Unsupported file format: {ext}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfaf260",
   "metadata": {},
   "source": [
    "## Step 4: Vector Store Implementation\n",
    "This step implements the `ChromaVectorStore` class for managing the vector database. It handles the storage and retrieval of document embeddings using ChromaDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a19f6dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ChromaVectorStore:\n",
    "    \"\"\"ChromaDB vector store implementation for document storage and retrieval\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 persist_directory: str = \"chroma_db\",\n",
    "                 embedding_model: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        self.persist_directory = persist_directory\n",
    "        self.collection_name = \"lecture_notes\"\n",
    "        \n",
    "        # Using sentence-transformers for embeddings\n",
    "        self.embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "            model_name=embedding_model\n",
    "        )\n",
    "        \n",
    "        self._init_client()\n",
    "    \n",
    "    def _init_client(self) -> None:\n",
    "        \"\"\"Initialize the ChromaDB client\"\"\"\n",
    "        os.makedirs(self.persist_directory, exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "            # Get or create collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                embedding_function=self.embedding_function,\n",
    "                metadata={\"description\": \"CTSE Lecture Notes\"}\n",
    "            )\n",
    "            logging.info(f\"ChromaDB initialized at {self.persist_directory}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to initialize ChromaDB: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def add_documents(self, documents: List[Dict[str, Any]]) -> None:\n",
    "        \"\"\"Add documents to vector store\n",
    "        \n",
    "        Args:\n",
    "            documents: List of document dicts with 'content' and 'metadata' keys\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Extract required fields\n",
    "            ids = [f\"doc_{i}\" for i in range(len(documents))]\n",
    "            texts = [doc['content'] for doc in documents]\n",
    "            metadatas = [doc['metadata'] for doc in documents]\n",
    "            \n",
    "            # Add documents to collection\n",
    "            self.collection.add(\n",
    "                documents=texts,\n",
    "                metadatas=metadatas,\n",
    "                ids=ids\n",
    "            )\n",
    "            logging.info(f\"Added {len(documents)} documents to ChromaDB\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to add documents to ChromaDB: {str(e)}\")\n",
    "    \n",
    "    def query(self, query_text: str, n_results: int = 5) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Query the vector store for similar documents\n",
    "        \n",
    "        Args:\n",
    "            query_text: The query string\n",
    "            n_results: Number of results to return\n",
    "            \n",
    "        Returns:\n",
    "            List of document dicts with content and metadata\n",
    "        \"\"\"\n",
    "        try:\n",
    "            results = self.collection.query(\n",
    "                query_texts=[query_text],\n",
    "                n_results=n_results\n",
    "            )\n",
    "            \n",
    "            # Format results\n",
    "            documents = []\n",
    "            for i, doc in enumerate(results['documents'][0]):\n",
    "                documents.append({\n",
    "                    'content': doc,\n",
    "                    'metadata': results['metadatas'][0][i],\n",
    "                    'id': results['ids'][0][i],\n",
    "                    'distance': results.get('distances', [[0] * n_results])[0][i]\n",
    "                })\n",
    "            \n",
    "            return documents\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Query failed: {str(e)}\")\n",
    "            return []\n",
    "    \n",
    "    def get_collection_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get stats about the collection\"\"\"\n",
    "        try:\n",
    "            count = self.collection.count()\n",
    "            return {\n",
    "                \"collection_name\": self.collection_name,\n",
    "                \"document_count\": count,\n",
    "                \"persist_directory\": self.persist_directory\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to get collection stats: {str(e)}\")\n",
    "            return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939f88a9",
   "metadata": {},
   "source": [
    "## Step 5: Retrieval Layer\n",
    "This step implements the `HaystackRetriever` class for hybrid retrieval. It combines semantic search using the vector store with keyword-based search using BM25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3527a25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HaystackRetriever:\n",
    "    \"\"\"Haystack-based document retriever for RAG\"\"\"\n",
    "    \n",
    "    def __init__(self, vector_store=None):\n",
    "        \"\"\"Initialize Haystack retriever\n",
    "        \n",
    "        Args:\n",
    "            vector_store: Optional ChromaVectorStore to use for retrieval\n",
    "        \"\"\"\n",
    "        self.vector_store = vector_store\n",
    "        \n",
    "        # In-memory document store for BM25\n",
    "        self.document_store = InMemoryDocumentStore()\n",
    "        self.bm25_retriever = InMemoryBM25Retriever(document_store=self.document_store)\n",
    "    \n",
    "    def add_documents(self, documents: List[Dict[str, Any]]) -> None:\n",
    "        \"\"\"Add documents to the retriever\n",
    "        \n",
    "        Args:\n",
    "            documents: List of document dicts with 'content' and 'metadata'\n",
    "        \"\"\"\n",
    "        haystack_docs = []\n",
    "        \n",
    "        for doc in documents:\n",
    "            haystack_docs.append(\n",
    "                Document(content=doc['content'], meta=doc['metadata'])\n",
    "            )\n",
    "        \n",
    "        try:\n",
    "            # Add to document store\n",
    "            self.document_store.write_documents(haystack_docs)\n",
    "            logging.info(f\"Added {len(haystack_docs)} documents to Haystack document store\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to add documents to Haystack: {str(e)}\")\n",
    "    \n",
    "    def retrieve(self, query: str, top_k: int = 5) -> List[Document]:\n",
    "        \"\"\"Retrieve relevant documents using BM25\n",
    "        \n",
    "        Args:\n",
    "            query: Query string\n",
    "            top_k: Number of documents to retrieve\n",
    "            \n",
    "        Returns:\n",
    "            List of Haystack Document objects\n",
    "        \"\"\"\n",
    "        try:\n",
    "            results = self.bm25_retriever.run(query=query, top_k=top_k)\n",
    "            documents = results[\"documents\"]\n",
    "            logging.info(f\"Retrieved {len(documents)} documents using BM25 retriever\")\n",
    "            return documents\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Haystack retrieval error: {str(e)}\")\n",
    "            return []\n",
    "    \n",
    "    def hybrid_retrieve(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Hybrid retrieval using both BM25 and vector search\n",
    "        \n",
    "        Args:\n",
    "            query: Query string\n",
    "            top_k: Number of documents to retrieve\n",
    "            \n",
    "        Returns:\n",
    "            List of document dicts\n",
    "        \"\"\"\n",
    "        if self.vector_store is None:\n",
    "            logging.warning(\"Vector store not available for hybrid search\")\n",
    "            return self._convert_to_dicts(self.retrieve(query, top_k))\n",
    "        \n",
    "        try:\n",
    "            # Get sparse results (BM25)\n",
    "            sparse_results = self.retrieve(query, top_k)\n",
    "            sparse_docs = self._convert_to_dicts(sparse_results)\n",
    "            \n",
    "            # Get dense results (Vector)\n",
    "            dense_docs = self.vector_store.query(query, top_k)\n",
    "            \n",
    "            # Combine results (simple approach - could be improved)\n",
    "            seen_contents = set()\n",
    "            hybrid_results = []\n",
    "            \n",
    "            # Add dense results first (prioritize semantic search)\n",
    "            for doc in dense_docs:\n",
    "                content_hash = hash(doc['content'])\n",
    "                if content_hash not in seen_contents:\n",
    "                    seen_contents.add(content_hash)\n",
    "                    doc['retrieval_method'] = 'vector'\n",
    "                    hybrid_results.append(doc)\n",
    "            \n",
    "            # Add sparse results that aren't duplicates\n",
    "            for doc in sparse_docs:\n",
    "                content_hash = hash(doc['content'])\n",
    "                if content_hash not in seen_contents:\n",
    "                    seen_contents.add(content_hash)\n",
    "                    doc['retrieval_method'] = 'bm25'\n",
    "                    hybrid_results.append(doc)\n",
    "            \n",
    "            # Trim to top_k\n",
    "            hybrid_results = hybrid_results[:top_k]\n",
    "            \n",
    "            logging.info(f\"Retrieved {len(hybrid_results)} documents using hybrid search\")\n",
    "            return hybrid_results\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Hybrid retrieval error: {str(e)}\")\n",
    "            return self._convert_to_dicts(self.retrieve(query, top_k))\n",
    "    \n",
    "    @staticmethod\n",
    "    def _convert_to_dicts(documents: List[Document]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Convert Haystack Document objects to dicts\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                'content': doc.content,\n",
    "                'metadata': doc.meta,\n",
    "                'id': doc.id,\n",
    "                'score': doc.score if hasattr(doc, 'score') else None\n",
    "            }\n",
    "            for doc in documents\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a26abb",
   "metadata": {},
   "source": [
    "## Step 6: LLM Interface\n",
    "This step implements the `OllamaLLM` class for interacting with the local LLM. It handles generating responses using the Ollama API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7d4dc939",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OllamaLLM:\n",
    "    \"\"\"Client for Ollama local LLM\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model: str = \"mistral:7b-instruct-v0.3-q4_1\",\n",
    "                 base_url: str = \"http://localhost:11434\",\n",
    "                 system_prompt: Optional[str] = None):\n",
    "        \"\"\"Initialize Ollama client\n",
    "        \n",
    "        Args:\n",
    "            model: Model name to use\n",
    "            base_url: Ollama API base URL\n",
    "            system_prompt: Optional system prompt to set context\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.base_url = base_url.rstrip('/')\n",
    "        self.api_url = f\"{self.base_url}/api/generate\"\n",
    "        self.system_prompt = system_prompt or SYSTEM_PROMPT\n",
    "        \n",
    "        # Check if Ollama is available\n",
    "        self._check_availability()\n",
    "    \n",
    "    def _check_availability(self) -> None:\n",
    "        \"\"\"Check if Ollama server is running\"\"\"\n",
    "        try:\n",
    "            response = requests.get(f\"{self.base_url}/api/tags\")\n",
    "            if response.status_code == 200:\n",
    "                models = response.json().get(\"models\", [])\n",
    "                model_names = [m.get(\"name\") for m in models]\n",
    "                \n",
    "                if not model_names:\n",
    "                    logging.warning(\"No models found in Ollama.\")\n",
    "                elif self.model not in model_names:\n",
    "                    logging.warning(f\"Model {self.model} not found. Available models: {', '.join(model_names)}\")\n",
    "                    logging.info(f\"You can pull it using: ollama pull {self.model}\")\n",
    "                else:\n",
    "                    logging.info(f\"Connected to Ollama. Using model: {self.model}\")\n",
    "            else:\n",
    "                logging.warning(f\"Ollama returned status code {response.status_code}\")\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            logging.error(f\"Cannot connect to Ollama at {self.base_url}. Is Ollama running?\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error checking Ollama availability: {str(e)}\")\n",
    "    \n",
    "    def generate(self, prompt: str, context: Optional[List[Dict[str, Any]]] = None) -> str:\n",
    "        \"\"\"Generate text from the LLM\n",
    "        \n",
    "        Args:\n",
    "            prompt: User prompt/question\n",
    "            context: Optional list of context documents\n",
    "            \n",
    "        Returns:\n",
    "            Generated text response\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not context:\n",
    "                # Simple query without RAG context\n",
    "                return self._simple_generate(prompt)\n",
    "            \n",
    "            # Generate RAG prompt\n",
    "            rag_prompt = RAG_PROMPT_TEMPLATE.format(\n",
    "                context=\"\\n\\n\".join([doc['content'] for doc in context]),\n",
    "                question=prompt\n",
    "            )\n",
    "            \n",
    "            payload = {\n",
    "                \"model\": self.model,\n",
    "                \"prompt\": rag_prompt,\n",
    "                \"stream\": False,\n",
    "                \"system\": self.system_prompt\n",
    "            }\n",
    "            \n",
    "            response = requests.post(self.api_url, json=payload)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                return response.json()[\"response\"]\n",
    "            else:\n",
    "                logging.error(f\"Ollama API error: {response.status_code} - {response.text}\")\n",
    "                return f\"Error: Failed to generate response from Ollama (Status {response.status_code})\"\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            logging.error(\"Connection to Ollama failed. Is Ollama running?\")\n",
    "            return (\n",
    "                \"# Connection Error\\n\\n\"\n",
    "                \"Cannot connect to Ollama. Please make sure the Ollama server is running.\\n\\n\"\n",
    "                \"To start Ollama:\\n\"\n",
    "                \"1. Open a new terminal\\n\"\n",
    "                \"2. Run the Ollama application\\n\"\n",
    "                \"3. Try your question again\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error generating from Ollama: {str(e)}\")\n",
    "            return f\"# Error\\n\\n{str(e)}\\n\\nPlease try again or check the logs for more information.\"\n",
    "    \n",
    "    def _simple_generate(self, prompt: str) -> str:\n",
    "        \"\"\"Generate response for a simple prompt without RAG context\n",
    "        \n",
    "        Args:\n",
    "            prompt: User prompt/question\n",
    "            \n",
    "        Returns:\n",
    "            Generated text response\n",
    "        \"\"\"\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False,\n",
    "            \"system\": self.system_prompt\n",
    "        }\n",
    "        \n",
    "        response = requests.post(self.api_url, json=payload)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response.json()[\"response\"]\n",
    "        else:\n",
    "            logging.error(f\"Ollama API error: {response.status_code} - {response.text}\")\n",
    "            return f\"Error: Failed to generate response from Ollama (Status {response.status_code})\"\n",
    "    \n",
    "    def list_models(self) -> List[str]:\n",
    "        \"\"\"List available models in Ollama\"\"\"\n",
    "        try:\n",
    "            response = requests.get(f\"{self.base_url}/api/tags\")\n",
    "            if response.status_code == 200:\n",
    "                return [model.get(\"name\") for model in response.json().get(\"models\", [])]\n",
    "            else:\n",
    "                logging.error(f\"Failed to list models: {response.status_code}\")\n",
    "                return []\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error listing models: {str(e)}\")\n",
    "            return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6427d25",
   "metadata": {},
   "source": [
    "## Step 7: Prompt Engineering\n",
    "This step implements the prompt engineering templates and helper functions for generating prompts. These templates ensure structured and contextually relevant responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "784d3d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_rag_prompt(question: str, context: List[Dict[str, Any]]) -> str:\n",
    "    \"\"\"Generate an advanced RAG prompt with chain-of-thought reasoning\n",
    "    \n",
    "    Args:\n",
    "        question: The user's question\n",
    "        context: List of context documents\n",
    "    \n",
    "    Returns:\n",
    "        Formatted prompt for the LLM\n",
    "    \"\"\"\n",
    "    # Format context documents into a unified text\n",
    "    context_text = format_context_documents(context)\n",
    "    \n",
    "    # Replace placeholders in the template\n",
    "    prompt = RAG_PROMPT_TEMPLATE.format(\n",
    "        context=context_text,\n",
    "        question=question\n",
    "    )\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def format_context_documents(context: List[Dict[str, Any]]) -> str:\n",
    "    \"\"\"Format context documents with metadata for better reference\n",
    "    \n",
    "    Args:\n",
    "        context: List of context documents\n",
    "    \n",
    "    Returns:\n",
    "        Formatted context text\n",
    "    \"\"\"\n",
    "    if not context:\n",
    "        return \"No relevant context information available.\"\n",
    "    \n",
    "    context_sections = []\n",
    "    \n",
    "    for i, doc in enumerate(context):\n",
    "        # Extract metadata\n",
    "        source = doc.get('metadata', {}).get('source', 'Unknown Source')\n",
    "        page_num = doc.get('metadata', {}).get('page_num', 'N/A')\n",
    "        content = doc.get('content', '').strip()\n",
    "        \n",
    "        # Calculate relevance if available\n",
    "        relevance = \"\"\n",
    "        if 'distance' in doc and doc['distance'] is not None:\n",
    "            similarity = 1.0 - float(doc['distance'])\n",
    "            relevance = f\" [Relevance: {similarity:.2f}]\"\n",
    "        \n",
    "        # Format document section\n",
    "        section = f\"[DOCUMENT {i+1}]: {source} (Page/Slide: {page_num}){relevance}\\n{content}\"\n",
    "        context_sections.append(section)\n",
    "    \n",
    "    return \"\\n\\n\" + \"\\n\\n\".join(context_sections)\n",
    "\n",
    "def get_structured_prompt(question: str, context: List[Dict[str, Any]], \n",
    "                         output_format: str = \"default\") -> str:\n",
    "    \"\"\"Generate a prompt requiring structured output in a specific format\n",
    "    \n",
    "    Args:\n",
    "        question: The user's question\n",
    "        context: List of context documents\n",
    "        output_format: The desired output format (default, table, steps, comparison)\n",
    "    \n",
    "    Returns:\n",
    "        Formatted prompt for the LLM\n",
    "    \"\"\"\n",
    "    context_text = format_context_documents(context)\n",
    "    \n",
    "    # Define different output format instructions\n",
    "    format_instructions = {\n",
    "        \"default\": \"\"\"\n",
    "Format your response using appropriate Markdown with:\n",
    "- Clear headings with ## and ### for sections\n",
    "- Bullet points for lists\n",
    "- **Bold** for important concepts\n",
    "- `code blocks` for technical terms or code\n",
    "- > blockquotes for definitions\n",
    "        \"\"\",\n",
    "        \n",
    "        \"table\": \"\"\"\n",
    "Include a Markdown table in your response to summarize key points:\n",
    "| Concept | Description | Example |\n",
    "| ------- | ----------- | ------- |\n",
    "| Concept 1 | Description 1 | Example 1 |\n",
    "| ... | ... | ... |\n",
    "        \"\"\",\n",
    "        \n",
    "        \"steps\": \"\"\"\n",
    "Format your response as a step-by-step guide using:\n",
    "## Process Overview\n",
    "Brief overview of the process\n",
    "\n",
    "## Step 1: [Step Name]\n",
    "Explanation of step 1\n",
    "\n",
    "## Step 2: [Step Name]\n",
    "Explanation of step 2\n",
    "\n",
    "And so on, with clear numbered steps and explanations.\n",
    "        \"\"\",\n",
    "        \n",
    "        \"comparison\": \"\"\"\n",
    "Format your response as a comparison between concepts:\n",
    "## Concept A\n",
    "- Key characteristics\n",
    "- Advantages\n",
    "- Disadvantages\n",
    "\n",
    "## Concept B\n",
    "- Key characteristics\n",
    "- Advantages\n",
    "- Disadvantages\n",
    "\n",
    "## Comparison\n",
    "| Aspect | Concept A | Concept B |\n",
    "| ------ | --------- | --------- |\n",
    "| Aspect 1 | Value for A | Value for B |\n",
    "| ... | ... | ... |\n",
    "        \"\"\"\n",
    "    }\n",
    "    \n",
    "    # Get the format instructions\n",
    "    format_instruction = format_instructions.get(output_format, format_instructions[\"default\"])\n",
    "    \n",
    "    # Create the structured prompt\n",
    "    structured_prompt = f\"\"\"\n",
    "You are a university-level educational assistant specialized in Current Trends in Software Engineering.\n",
    "\n",
    "Based on the following context information from CTSE lecture notes:\n",
    "{context_text}\n",
    "\n",
    "Please answer this question:\n",
    "{question}\n",
    "\n",
    "{format_instruction}\n",
    "\n",
    "Be concise but comprehensive, and ensure all information is accurate according to the provided context.\n",
    "    \"\"\"\n",
    "    \n",
    "    return structured_prompt\n",
    "\n",
    "def _detect_appropriate_format(question: str) -> str:\n",
    "    \"\"\"Detect the most appropriate output format based on the question\n",
    "    \n",
    "    Args:\n",
    "        question: The user question\n",
    "    \n",
    "    Returns:\n",
    "        Suggested output format\n",
    "    \"\"\"\n",
    "    question_lower = question.lower()\n",
    "    \n",
    "    # Check for step-by-step requests\n",
    "    if any(phrase in question_lower for phrase in [\"steps\", \"process\", \"how to\", \"procedure\", \"workflow\"]):\n",
    "        return \"steps\"\n",
    "    \n",
    "    # Check for comparison requests\n",
    "    if any(phrase in question_lower for phrase in [\"compare\", \"difference between\", \"versus\", \"vs\", \"pros and cons\"]):\n",
    "        return \"comparison\"\n",
    "    \n",
    "    # Check for listing/table appropriate requests\n",
    "    if any(phrase in question_lower for phrase in [\"list\", \"summarize\", \"overview\", \"key aspects\", \"characteristics\"]):\n",
    "        return \"table\"\n",
    "    \n",
    "    # Default format for other questions\n",
    "    return \"default\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2010c12",
   "metadata": {},
   "source": [
    "## Step 8: Terminal UI\n",
    "This step implements the `TerminalUI` class for the Rich-powered terminal interface. It provides an interactive and visually appealing user interface for the chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9c7a385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TerminalUI:\n",
    "    \"\"\"Terminal UI using Rich for the chatbot interface\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 generate_fn: Callable[[str], str],\n",
    "                 history_capacity: int = 10,\n",
    "                 system_info: Dict[str, Any] = None,\n",
    "                 model_switch_fn: Optional[Callable[[str], bool]] = None):\n",
    "        \"\"\"Initialize the terminal UI\n",
    "        \n",
    "        Args:\n",
    "            generate_fn: Function that takes a question and returns an answer\n",
    "            history_capacity: Maximum number of conversations to keep in history\n",
    "            system_info: Dictionary containing system information to display\n",
    "            model_switch_fn: Function to switch between different models\n",
    "        \"\"\"\n",
    "        self.console = Console()\n",
    "        self.generate_fn = generate_fn\n",
    "        self.history = []\n",
    "        self.history_capacity = history_capacity\n",
    "        self.system_info = system_info or {}\n",
    "        self.model_switch_fn = model_switch_fn\n",
    "        \n",
    "        # Theme colors\n",
    "        self.theme = {\n",
    "            \"accent\": \"blue\",\n",
    "            \"secondary\": \"cyan\",\n",
    "            \"success\": \"green\",\n",
    "            \"warning\": \"yellow\",\n",
    "            \"error\": \"red\",\n",
    "            \"muted\": \"dim white\"\n",
    "        }\n",
    "        \n",
    "        # Clear screen on start\n",
    "        os.system('cls' if os.name == 'nt' else 'clear')\n",
    "    \n",
    "    def show_splash_screen(self):\n",
    "        \"\"\"Show an animated splash screen\"\"\"\n",
    "        with Progress(\n",
    "            SpinnerColumn(),\n",
    "            TextColumn(\"[bold blue]Initializing RagChitChat...[/]\"),\n",
    "            BarColumn(bar_width=40),\n",
    "            TaskProgressColumn(),\n",
    "            transient=True\n",
    "        ) as progress:\n",
    "            task = progress.add_task(\"[cyan]Loading components...\", total=100)\n",
    "            \n",
    "            for i in range(101):\n",
    "                time.sleep(0.015)  # Adjust for faster/slower animation\n",
    "                progress.update(task, completed=i, \n",
    "                               description=f\"[cyan]{self._get_loading_message(i)}[/]\")\n",
    "        \n",
    "        self._display_logo()\n",
    "    \n",
    "    def _get_loading_message(self, progress):\n",
    "        \"\"\"Return different messages based on loading progress\"\"\"\n",
    "        if progress < 20:\n",
    "            return \"Initializing components...\"\n",
    "        elif progress < 40:\n",
    "            return \"Loading document store...\"\n",
    "        elif progress < 60:\n",
    "            return \"Warming up embeddings...\"\n",
    "        elif progress < 80:\n",
    "            return \"Connecting to Ollama...\"\n",
    "        else:\n",
    "            return \"Almost ready...\"\n",
    "    \n",
    "    def _display_logo(self):\n",
    "        \"\"\"Display the app logo\"\"\"\n",
    "        logo = \"\"\"\n",
    "  _____              _____ _     _ _    _____ _           _   \n",
    " |  __ \\\\            / ____| |   (_) |  / ____| |         | |  \n",
    " | |__) |__ _  __ _| |    | |__  _| |_| |    | |__   __ _| |_ \n",
    " |  _  // _` |/ _` | |    | '_ \\\\| | __| |    | '_ \\\\ / _` | __|\n",
    " | | \\\\ \\\\ (_| | (_| | |____| | | | | |_| |____| | | | (_| | |_ \n",
    " |_|  \\\\_\\\\__,_|\\\\__, |\\\\_____|_| |_|_|\\\\__|\\\\_____|_| |_|\\\\__,_|\\\\__|\n",
    "               __/ |                                          \n",
    "              |___/                                           \n",
    "        \"\"\"\n",
    "        \n",
    "        self.console.print(Panel(f\"[bold {self.theme['accent']}]{logo}[/]\", \n",
    "                               border_style=self.theme[\"accent\"],\n",
    "                               subtitle=\"[white]Your AI assistant for CTSE Lecture Notes[/]\"))\n",
    "    \n",
    "    def show_welcome(self):\n",
    "        \"\"\"Display welcome message and instructions\"\"\"\n",
    "        self.show_splash_screen()\n",
    "        \n",
    "        # Show system info\n",
    "        if self.system_info:\n",
    "            self.show_system_info()\n",
    "        \n",
    "        self.console.print()\n",
    "        self.console.print(Panel(\n",
    "            \"[bold]Ask me anything about Current Trends in Software Engineering![/]\\n\\n\"\n",
    "            \"I can answer questions about CTSE lecture content, explain concepts,\\n\"\n",
    "            \"and help you understand course materials better.\",\n",
    "            title=f\"[{self.theme['secondary']}]How to use RagChitChat[/]\",\n",
    "            border_style=self.theme[\"secondary\"],\n",
    "            expand=False\n",
    "        ))\n",
    "        \n",
    "        self.console.print(Align(\n",
    "            \"\\nType [bold cyan]/help[/bold cyan] for commands or [bold cyan]/exit[/bold cyan] to quit.\\n\", \n",
    "            align=\"center\"\n",
    "        ))\n",
    "    \n",
    "    def show_system_info(self):\n",
    "        \"\"\"Display system information\"\"\"\n",
    "        table = Table(box=box.ROUNDED, title=\"System Information\", border_style=self.theme[\"secondary\"])\n",
    "        \n",
    "        table.add_column(\"Component\", style=f\"bold {self.theme['secondary']}\")\n",
    "        table.add_column(\"Details\", style=\"white\")\n",
    "        \n",
    "        # Add system info rows\n",
    "        for key, value in self.system_info.items():\n",
    "            # Format keys and values nicely\n",
    "            key_display = key.replace('_', ' ').title()\n",
    "            if isinstance(value, (list, tuple)):\n",
    "                value_display = ', '.join(str(v) for v in value)\n",
    "            elif isinstance(value, dict):\n",
    "                value_display = ', '.join(f\"{k}: {v}\" for k, v in value.items())\n",
    "            else:\n",
    "                value_display = str(value)\n",
    "                \n",
    "            table.add_row(key_display, value_display)\n",
    "            \n",
    "        self.console.print(Align(table, align=\"center\"))\n",
    "    \n",
    "    def show_help(self):\n",
    "        \"\"\"Display help information\"\"\"\n",
    "        table = Table(box=box.ROUNDED, title=\"Available Commands\", border_style=self.theme[\"accent\"])\n",
    "        \n",
    "        table.add_column(\"Command\", style=f\"bold {self.theme['secondary']}\")\n",
    "        table.add_column(\"Description\")\n",
    "        \n",
    "        table.add_row(\"/help\", \"Show this help message\")\n",
    "        table.add_row(\"/exit\", \"Exit the chatbot\")\n",
    "        table.add_row(\"/clear\", \"Clear the conversation history\")\n",
    "        table.add_row(\"/history\", \"Show conversation history\")\n",
    "        table.add_row(\"/info\", \"Show system information\")\n",
    "        table.add_row(\"/about\", \"About this application\")\n",
    "        table.add_row(\"/models\", \"List available models\")\n",
    "        table.add_row(\"/model <name>\", \"Switch to a different model\")\n",
    "        \n",
    "        self.console.print(Align(table, align=\"center\"))\n",
    "        \n",
    "        # Show example questions\n",
    "        examples = Table(\n",
    "            box=box.SIMPLE,\n",
    "            title=\"Example Questions\",\n",
    "            show_header=False,\n",
    "            border_style=self.theme[\"muted\"]\n",
    "        )\n",
    "        \n",
    "        examples.add_column(\"\", style=self.theme[\"secondary\"])\n",
    "        \n",
    "        examples.add_row(\"- What is continuous integration?\")\n",
    "        examples.add_row(\"- Explain the difference between DevOps and DevSecOps\")\n",
    "        examples.add_row(\"- What are the benefits of microservices architecture?\")\n",
    "        examples.add_row(\"- How does containerization improve software deployment?\")\n",
    "        \n",
    "        self.console.print(Panel(examples, border_style=self.theme[\"muted\"], expand=False))\n",
    "    \n",
    "    def show_about(self):\n",
    "        \"\"\"Display information about the application\"\"\"\n",
    "        about_text = \"\"\"\n",
    "RagChitChat is a Retrieval-Augmented Generation (RAG) chatbot designed to help students\n",
    "learn about Current Trends in Software Engineering. It uses:\n",
    "\n",
    "• [bold]Local LLM[/bold] via [link=https://ollama.ai]Ollama[/link] for AI inference\n",
    "• [bold]RAG Pipeline[/bold] with Haystack for intelligent document retrieval\n",
    "• [bold]Vector Database[/bold] using ChromaDB for semantic search\n",
    "• [bold]Rich UI[/bold] in the terminal for a pleasant user experience\n",
    "\n",
    "This project demonstrates how generative AI can be applied to educational contexts\n",
    "while maintaining privacy by keeping all operations local.\n",
    "\n",
    "[dim italic]Created by Nadun for the CTSE module assignment[/dim italic]\n",
    "        \"\"\"\n",
    "        \n",
    "        self.console.print(Panel(\n",
    "            Markdown(about_text),\n",
    "            title=\"About RagChitChat\",\n",
    "            border_style=self.theme[\"accent\"],\n",
    "            padding=(1, 2)\n",
    "        ))\n",
    "    \n",
    "    def show_history(self, page: int = 1, items_per_page: int = 5):\n",
    "        \"\"\"Display conversation history with pagination\n",
    "        \n",
    "        Args:\n",
    "            page: Page number to display\n",
    "            items_per_page: Number of conversations per page\n",
    "        \"\"\"\n",
    "        if not self.history:\n",
    "            self.console.print(Panel(\n",
    "                \"[italic]You haven't asked any questions yet.[/]\", \n",
    "                border_style=self.theme[\"warning\"],\n",
    "                title=\"History Empty\"\n",
    "            ))\n",
    "            return\n",
    "        \n",
    "        # Calculate pagination\n",
    "        start_idx = (page - 1) * items_per_page\n",
    "        end_idx = start_idx + items_per_page\n",
    "        current_items = self.history[start_idx:end_idx]\n",
    "        total_pages = (len(self.history) + items_per_page - 1) // items_per_page\n",
    "        \n",
    "        # Create paginated display\n",
    "        self.console.print(Rule(f\"[bold]Conversation History (Page {page}/{total_pages})[/]\"))\n",
    "        \n",
    "        for i, (question, answer) in enumerate(current_items, start=start_idx+1):\n",
    "            self.console.print()\n",
    "            self.console.print(Panel(\n",
    "                f\"[bold {self.theme['secondary']}]Q: {question}[/]\",\n",
    "                border_style=self.theme[\"secondary\"],\n",
    "                padding=(0, 1)\n",
    "            ))\n",
    "            \n",
    "            try:\n",
    "                # Try to render as markdown\n",
    "                self.console.print(Panel(\n",
    "                    Markdown(answer),\n",
    "                    border_style=self.theme[\"success\"],\n",
    "                    padding=(0, 1)\n",
    "                ))\n",
    "            except Exception:\n",
    "                # Fallback to plain text\n",
    "                self.console.print(Panel(\n",
    "                    answer,\n",
    "                    border_style=self.theme[\"success\"],\n",
    "                    padding=(0, 1)\n",
    "                ))\n",
    "        \n",
    "        # Pagination controls\n",
    "        self.console.print()\n",
    "        if total_pages > 1:\n",
    "            pagination = \"\"\n",
    "            if page > 1:\n",
    "                pagination += \"[bold]/prev[/] \"\n",
    "            pagination += f\"Page {page}/{total_pages}\"\n",
    "            if page < total_pages:\n",
    "                pagination += \" [bold]/next[/]\"\n",
    "                \n",
    "            self.console.print(Align(pagination, align=\"center\"))\n",
    "    \n",
    "    def handle_question(self, question: str) -> None:\n",
    "        \"\"\"Process a user question and display the response\n",
    "        \n",
    "        Args:\n",
    "            question: User's question text\n",
    "        \"\"\"\n",
    "        # Display the question banner\n",
    "        self.console.print()\n",
    "        self.console.print(Panel(\n",
    "            f\"[bold]{question}[/]\", \n",
    "            border_style=self.theme[\"accent\"],\n",
    "            title=\"Question\"\n",
    "        ))\n",
    "        \n",
    "        # Show spinner while generating response\n",
    "        with Progress(\n",
    "            SpinnerColumn(),\n",
    "            TextColumn(\"Thinking...\"),\n",
    "            BarColumn(),\n",
    "            TextColumn(\"[bold cyan]{task.description}[/bold cyan]\"),\n",
    "            expand=True\n",
    "        ) as progress:\n",
    "            retrieval_task = progress.add_task(\"Retrieving context...\", total=None)\n",
    "            \n",
    "            # Use closure to update progress\n",
    "            def progress_callback(stage, details=None):\n",
    "                if stage == \"retrieval_complete\":\n",
    "                    progress.update(retrieval_task, description=\"Generating answer...\")\n",
    "            \n",
    "            # Record time for response metrics\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Generate response\n",
    "            answer = self.generate_fn(question, progress_callback)\n",
    "            \n",
    "            # Calculate response time\n",
    "            elapsed = time.time() - start_time\n",
    "        \n",
    "        # Store in history\n",
    "        self.history.append((question, answer))\n",
    "        if len(self.history) > self.history_capacity:\n",
    "            self.history.pop(0)\n",
    "        \n",
    "        # Display the response\n",
    "        self.console.print()\n",
    "        self.console.print(f\"[{self.theme['muted']}]Generated in {elapsed:.2f}s[/]\")\n",
    "        \n",
    "        try:\n",
    "            # Try to render as markdown\n",
    "            self.console.print(Panel(\n",
    "                Markdown(answer),\n",
    "                border_style=self.theme[\"success\"],\n",
    "                title=\"Answer\",\n",
    "                padding=(1, 2)\n",
    "            ))\n",
    "        except Exception:\n",
    "            # Fallback to plain text\n",
    "            self.console.print(Panel(\n",
    "                answer,\n",
    "                border_style=self.theme[\"success\"],\n",
    "                title=\"Answer\",\n",
    "                padding=(1, 2)\n",
    "            ))\n",
    "    \n",
    "    def list_available_models(self):\n",
    "        \"\"\"Display available models that can be selected\"\"\"\n",
    "        if not self.model_switch_fn or not self.system_info or 'available_models' not in self.system_info:\n",
    "            self.console.print(Panel(\n",
    "                \"[italic]Model switching is not available.[/]\", \n",
    "                border_style=self.theme[\"warning\"],\n",
    "                title=\"Models\"\n",
    "            ))\n",
    "            return\n",
    "            \n",
    "        # Get current model and available models\n",
    "        current_model = self.system_info.get('current_model', 'unknown')\n",
    "        models = self.system_info.get('available_models', [])\n",
    "        \n",
    "        if not models:\n",
    "            self.console.print(Panel(\n",
    "                \"[italic]No models found in Ollama. You can pull models using the Ollama CLI:[/]\\n\" +\n",
    "                \"ollama pull mistral:7b-instruct-v0.3-q4_1\", \n",
    "                border_style=self.theme[\"warning\"],\n",
    "                title=\"No Models Available\"\n",
    "            ))\n",
    "            return\n",
    "            \n",
    "        # Create a table of models\n",
    "        table = Table(title=\"Available Models\", box=box.ROUNDED, border_style=self.theme[\"secondary\"])\n",
    "        table.add_column(\"Model\", style=f\"bold {self.theme['secondary']}\")\n",
    "        table.add_column(\"Status\")\n",
    "        \n",
    "        for model in models:\n",
    "            if model == current_model:\n",
    "                table.add_row(model, f\"[{self.theme['success']}]ACTIVE[/]\")\n",
    "            else:\n",
    "                table.add_row(model, \"\")\n",
    "                \n",
    "        self.console.print(Panel(\n",
    "            table,\n",
    "            border_style=self.theme[\"secondary\"],\n",
    "            title=\"Available Models\"\n",
    "        ))\n",
    "        \n",
    "        self.console.print(\"\\nTo switch models, use: [bold]/model model_name[/]\")\n",
    "        \n",
    "    def switch_model(self, model_name: str):\n",
    "        \"\"\"Switch to a different model\n",
    "        \n",
    "        Args:\n",
    "            model_name: Name of the model to switch to\n",
    "        \"\"\"\n",
    "        if not self.model_switch_fn:\n",
    "            self.console.print(Panel(\n",
    "                \"[italic]Model switching is not available.[/]\", \n",
    "                border_style=self.theme[\"warning\"],\n",
    "                title=\"Models\"\n",
    "            ))\n",
    "            return\n",
    "            \n",
    "        # Show loading indicator while switching model\n",
    "        with Progress(\n",
    "            SpinnerColumn(),\n",
    "            TextColumn(f\"[cyan]Switching to model {model_name}...[/cyan]\"),\n",
    "            transient=True\n",
    "        ) as progress:\n",
    "            task = progress.add_task(\"\", total=None)\n",
    "            \n",
    "            # Try to switch the model\n",
    "            success = self.model_switch_fn(model_name)\n",
    "        \n",
    "        # Show the result\n",
    "        if success:\n",
    "            # Update the current model in system info\n",
    "            if self.system_info and 'current_model' in self.system_info:\n",
    "                self.system_info['current_model'] = model_name\n",
    "                \n",
    "            self.console.print(Panel(\n",
    "                f\"[bold]Successfully switched to model: [green]{model_name}[/green][/]\",\n",
    "                border_style=self.theme[\"success\"],\n",
    "                title=\"Model Switched\"\n",
    "            ))\n",
    "        else:\n",
    "            self.console.print(Panel(\n",
    "                f\"[bold]Failed to switch to model: [red]{model_name}[/red][/]\\n\\n\"\n",
    "                f\"Make sure the model is available in Ollama.\\n\"\n",
    "                f\"You can pull it using: ollama pull {model_name}\",\n",
    "                border_style=self.theme[\"error\"],\n",
    "                title=\"Error\"\n",
    "            ))\n",
    "    \n",
    "    def run(self) -> None:\n",
    "        \"\"\"Run the main chat loop\"\"\"\n",
    "        self.show_welcome()\n",
    "        \n",
    "        # Main interaction loop\n",
    "        current_history_page = 1\n",
    "        while True:\n",
    "            self.console.print()\n",
    "            question = Prompt.ask(f\"[bold {self.theme['accent']}]Ask a question (or type /help)[/]\")\n",
    "            \n",
    "            # Handle commands\n",
    "            if question.lower() == \"/exit\":\n",
    "                if Confirm.ask(\"[yellow]Are you sure you want to exit?[/]\"):\n",
    "                    self.console.print(\"[yellow]Thank you for using RagChitChat! Goodbye![/]\")\n",
    "                    break\n",
    "            elif question.lower() == \"/help\":\n",
    "                self.show_help()\n",
    "            elif question.lower() == \"/clear\":\n",
    "                self.history = []\n",
    "                os.system('cls' if os.name == 'nt' else 'clear')\n",
    "                self.show_welcome()\n",
    "            elif question.lower() == \"/history\":\n",
    "                current_history_page = 1\n",
    "                self.show_history(page=current_history_page)\n",
    "            elif question.lower() == \"/next\" and self.history:\n",
    "                current_history_page += 1\n",
    "                self.show_history(page=current_history_page)\n",
    "            elif question.lower() == \"/prev\" and self.history:\n",
    "                current_history_page = max(1, current_history_page - 1)\n",
    "                self.show_history(page=current_history_page)\n",
    "            elif question.lower() == \"/info\":\n",
    "                self.show_system_info()\n",
    "            elif question.lower() == \"/about\":\n",
    "                self.show_about()\n",
    "            elif question.lower() == \"/models\":\n",
    "                self.list_available_models()\n",
    "            elif question.lower().startswith(\"/model \"):\n",
    "                model_name = question[7:].strip()\n",
    "                if model_name:\n",
    "                    self.switch_model(model_name)\n",
    "                else:\n",
    "                    self.console.print(\"[yellow]Please specify a model name. Example: /model mistral-7b[/]\")\n",
    "            elif question.strip():\n",
    "                # Process regular questions\n",
    "                self.handle_question(question)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a372199",
   "metadata": {},
   "source": [
    "## Step 9: Main Application Logic\n",
    "This step implements the main application logic (`RagChitChat` class) to integrate all components and run the chatbot. This class serves as the entry point for the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "75d52e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 17:27:50,874 - root - INFO - ChromaDB initialized at chroma_db\n",
      "2025-05-08 17:27:50,972 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=2, read=2, redirect=None, status=None)) after connection broken by 'SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')': /batch/\n",
      "2025-05-08 17:27:50,972 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=2, read=2, redirect=None, status=None)) after connection broken by 'SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')': /batch/\n",
      "2025-05-08 17:27:50,986 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=2, read=2, redirect=None, status=None)) after connection broken by 'SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')': /batch/\n",
      "2025-05-08 17:27:50,986 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=2, read=2, redirect=None, status=None)) after connection broken by 'SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')': /batch/\n",
      "2025-05-08 17:27:51,489 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=2, read=2, redirect=None, status=None)) after connection broken by 'SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')': /batch/\n",
      "2025-05-08 17:27:51,489 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=2, read=2, redirect=None, status=None)) after connection broken by 'SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')': /batch/\n",
      "2025-05-08 17:27:51,505 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=2, read=2, redirect=None, status=None)) after connection broken by 'SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')': /batch/\n",
      "2025-05-08 17:27:51,505 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=2, read=2, redirect=None, status=None)) after connection broken by 'SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')': /batch/\n",
      "2025-05-08 17:27:51,676 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=2, read=2, redirect=None, status=None)) after connection broken by 'SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')': /batch/\n",
      "2025-05-08 17:27:51,676 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=2, read=2, redirect=None, status=None)) after connection broken by 'SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')': /batch/\n",
      "2025-05-08 17:27:51,692 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=2, read=2, redirect=None, status=None)) after connection broken by 'SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')': /batch/\n",
      "2025-05-08 17:27:51,692 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=2, read=2, redirect=None, status=None)) after connection broken by 'SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')': /batch/\n",
      "2025-05-08 17:27:52,908 - root - INFO - Connected to Ollama. Using model: mistral:7b-instruct-v0.3-q4_1\n",
      "2025-05-08 17:27:52,909 - __main__ - INFO - Using existing processed lecture notes\n",
      "2025-05-08 17:27:52,908 - root - INFO - Connected to Ollama. Using model: mistral:7b-instruct-v0.3-q4_1\n",
      "2025-05-08 17:27:52,909 - __main__ - INFO - Using existing processed lecture notes\n",
      "2025-05-08 17:27:53,776 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=2, read=2, redirect=None, status=None)) after connection broken by 'SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')': /batch/\n",
      "2025-05-08 17:27:53,777 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=2, read=2, redirect=None, status=None)) after connection broken by 'SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')': /batch/\n",
      "2025-05-08 17:27:53,776 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=2, read=2, redirect=None, status=None)) after connection broken by 'SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')': /batch/\n",
      "2025-05-08 17:27:53,777 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=2, read=2, redirect=None, status=None)) after connection broken by 'SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')': /batch/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b69fff5141264f76902abcad9374242c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">  _____              _____ _     _ _    _____ _           _   </span>                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> |  __ \\            / ____| |   (_) |  / ____| |         | |  </span>                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> | |__) |__ _  __ _| |    | |__  _| |_| |    | |__   __ _| |_ </span>                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> |  _  // _` |/ _` | |    | '_ \\| | __| |    | '_ \\ / _` | __|</span>                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> | | \\ \\ (_| | (_| | |____| | | | | |_| |____| | | | (_| | |_ </span>                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> |_|  \\_\\__,_|\\__, |\\_____|_| |_|_|\\__|\\_____|_| |_|\\__,_|\\__|</span>                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">               __/ |                                          </span>                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">              |___/                                           </span>                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">        </span>                                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────── </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Your AI assistant for CTSE Lecture Notes</span><span style=\"color: #000080; text-decoration-color: #000080\"> ────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m  _____              _____ _     _ _    _____ _           _   \u001b[0m                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m |  __ \\            / ____| |   (_) |  / ____| |         | |  \u001b[0m                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m | |__) |__ _  __ _| |    | |__  _| |_| |    | |__   __ _| |_ \u001b[0m                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m |  _  // _` |/ _` | |    | '_ \\| | __| |    | '_ \\ / _` | __|\u001b[0m                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m | | \\ \\ (_| | (_| | |____| | | | | |_| |____| | | | (_| | |_ \u001b[0m                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m |_|  \\_\\__,_|\\__, |\\_____|_| |_|_|\\__|\\_____|_| |_|\\__,_|\\__|\u001b[0m                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m               __/ |                                          \u001b[0m                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m              |___/                                           \u001b[0m                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;34m        \u001b[0m                                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─\u001b[0m\u001b[34m──────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[37mYour AI assistant for CTSE Lecture Notes\u001b[0m\u001b[34m \u001b[0m\u001b[34m───────────────────────────────────\u001b[0m\u001b[34m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                System Information                                                 </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">╭──────────────────┬──────────────────────────────────────────────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span><span style=\"font-weight: bold\"> Component        </span><span style=\"color: #008080; text-decoration-color: #008080\">│</span><span style=\"font-weight: bold\"> Details                                                                                      </span><span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">├──────────────────┼──────────────────────────────────────────────────────────────────────────────────────────────┤</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Current Model    </span><span style=\"color: #008080; text-decoration-color: #008080\">│</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> mistral:7b-instruct-v0.3-q4_1                                                                </span><span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Available Models </span><span style=\"color: #008080; text-decoration-color: #008080\">│</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> mistral:7b-instruct-v0.3-q4_1, gemma3:4b-it-q8_0, deepseek-r1:14b                            </span><span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Document Count   </span><span style=\"color: #008080; text-decoration-color: #008080\">│</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> 1350                                                                                         </span><span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Processed Files  </span><span style=\"color: #008080; text-decoration-color: #008080\">│</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> lecture 1 part 1.txt, lecture 1 part 2.txt, lecture 2 part 1.txt, lecture 2 part 2.txt,      </span><span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">                  </span><span style=\"color: #008080; text-decoration-color: #008080\">│</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> lecture 3 part 1.txt, ...                                                                    </span><span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Vector Db        </span><span style=\"color: #008080; text-decoration-color: #008080\">│</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> ChromaDB                                                                                     </span><span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">╰──────────────────┴──────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                System Information                                                 \u001b[0m\n",
       "\u001b[36m╭──────────────────┬──────────────────────────────────────────────────────────────────────────────────────────────╮\u001b[0m\n",
       "\u001b[36m│\u001b[0m\u001b[1m \u001b[0m\u001b[1mComponent       \u001b[0m\u001b[1m \u001b[0m\u001b[36m│\u001b[0m\u001b[1m \u001b[0m\u001b[1mDetails                                                                                     \u001b[0m\u001b[1m \u001b[0m\u001b[36m│\u001b[0m\n",
       "\u001b[36m├──────────────────┼──────────────────────────────────────────────────────────────────────────────────────────────┤\u001b[0m\n",
       "\u001b[36m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mCurrent Model   \u001b[0m\u001b[1;36m \u001b[0m\u001b[36m│\u001b[0m\u001b[37m \u001b[0m\u001b[37mmistral:7b-instruct-v0.3-q4_1                                                               \u001b[0m\u001b[37m \u001b[0m\u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mAvailable Models\u001b[0m\u001b[1;36m \u001b[0m\u001b[36m│\u001b[0m\u001b[37m \u001b[0m\u001b[37mmistral:7b-instruct-v0.3-q4_1, gemma3:4b-it-q8_0, deepseek-r1:14b                           \u001b[0m\u001b[37m \u001b[0m\u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mDocument Count  \u001b[0m\u001b[1;36m \u001b[0m\u001b[36m│\u001b[0m\u001b[37m \u001b[0m\u001b[37m1350                                                                                        \u001b[0m\u001b[37m \u001b[0m\u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mProcessed Files \u001b[0m\u001b[1;36m \u001b[0m\u001b[36m│\u001b[0m\u001b[37m \u001b[0m\u001b[37mlecture 1 part 1.txt, lecture 1 part 2.txt, lecture 2 part 1.txt, lecture 2 part 2.txt,     \u001b[0m\u001b[37m \u001b[0m\u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m\u001b[1;36m                  \u001b[0m\u001b[36m│\u001b[0m\u001b[37m \u001b[0m\u001b[37mlecture 3 part 1.txt, ...                                                                   \u001b[0m\u001b[37m \u001b[0m\u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mVector Db       \u001b[0m\u001b[1;36m \u001b[0m\u001b[36m│\u001b[0m\u001b[37m \u001b[0m\u001b[37mChromaDB                                                                                    \u001b[0m\u001b[37m \u001b[0m\u001b[36m│\u001b[0m\n",
       "\u001b[36m╰──────────────────┴──────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">╭─────────────────────── How to use RagChitChat ───────────────────────╮</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span> <span style=\"font-weight: bold\">Ask me anything about Current Trends in Software Engineering!</span>        <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                      <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span> I can answer questions about CTSE lecture content, explain concepts, <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span> and help you understand course materials better.                     <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">╰──────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m╭─\u001b[0m\u001b[36m──────────────────────\u001b[0m\u001b[36m \u001b[0m\u001b[36mHow to use RagChitChat\u001b[0m\u001b[36m \u001b[0m\u001b[36m──────────────────────\u001b[0m\u001b[36m─╮\u001b[0m\n",
       "\u001b[36m│\u001b[0m \u001b[1mAsk me anything about Current Trends in Software Engineering!\u001b[0m        \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m                                                                      \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m I can answer questions about CTSE lecture content, explain concepts, \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m and help you understand course materials better.                     \u001b[36m│\u001b[0m\n",
       "\u001b[36m╰──────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                   \n",
       "                                     Type <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">/help</span> for commands or <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">/exit</span> to quit.                                     \n",
       "                                                                                                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                                                                                                   \n",
       "                                     Type \u001b[1;36m/\u001b[0m\u001b[1;36mhelp\u001b[0m for commands or \u001b[1;36m/\u001b[0m\u001b[1;36mexit\u001b[0m to quit.                                     \n",
       "                                                                                                                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Ask a question (or type /help)</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mAsk a question (or type /help)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭─────────────────────────────────────────────────── Question ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"font-weight: bold\">tell me about microservices</span>                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m──────────────────────────────────────────────────\u001b[0m\u001b[34m Question \u001b[0m\u001b[34m───────────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1mtell me about microservices\u001b[0m                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778dda1595c34aaaac1e5fea601a8af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 17:28:08,792 - haystack.document_stores.in_memory.document_store - INFO - No documents found for BM25 retrieval. Returning empty list.\n",
      "2025-05-08 17:28:08,793 - root - INFO - Retrieved 0 documents using BM25 retriever\n",
      "2025-05-08 17:28:08,793 - root - INFO - Retrieved 0 documents using BM25 retriever\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7037162e60545fe972ba4103a130b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 17:28:08,815 - root - INFO - Retrieved 5 documents using hybrid search\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\">Generated in </span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">19.</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\">68s</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;37mGenerated in \u001b[0m\u001b[1;2;37m19.\u001b[0m\u001b[2;37m68s\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭──────────────────────────────────────────────────── Answer ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                           <span style=\"font-weight: bold; text-decoration: underline\">Microservices Architecture</span>                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  Microservices are a distinct and organized approach to developing software applications. This architectural    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  style decomposes an application into several small, independent services. Each microservice handles a          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  specific functionality or business capability and communicates with other services through well-defined        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  interfaces (APIs).                                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                     <span style=\"font-weight: bold\">Benefits of Microservices Architecture</span>                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">Flexibility</span>: Microservices allow for greater agility as each service can be developed, deployed, and        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>scaled independently.                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">Technology Selection</span>: Each microservice can be built using the most appropriate technology stack for its    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>specific requirements.                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">Isolation</span>: Failure in one microservice does not impact the entire system, enhancing reliability and fault   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>tolerance.                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 4 </span><span style=\"font-weight: bold\">Innovation</span>: Teams working on different microservices can innovate quickly without being hindered by other   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>parts of the application.                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                    <span style=\"font-weight: bold\">Challenges of Microservices Architecture</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">Complexity</span>: Managing many small services can lead to a complex system, making it more difficult to          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>maintain and troubleshoot.                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">Inter-service communication</span>: Proper communication between microservices should be well designed to          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>minimize latency and ensure data consistency.                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">Data management</span>: Sharing data between microservices may become problematic due to possible inconsistencies  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>and duplication issues.                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 4 </span><span style=\"font-weight: bold\">Deployment and orchestration</span>: Automating the deployment, scaling, and monitoring of multiple microservices  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>is crucial for efficient operation.                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                          <span style=\"font-weight: bold\">Introduction to Microservices</span>                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  Microservices were not pre-planned but evolved as a response to practical needs in software development.       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  Responding to Change is one of the main reasons behind their emergence, offering the agility and flexibility   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  required to adapt to new technologies and market demands.                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  [Note: The lecture notes do not provide information about design patterns related to microservices, but I can  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  tell you that they are important when designing and managing microservices in a system.]                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #808000; text-decoration-color: #808000\">─────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                      <span style=\"font-weight: bold\">Example of Microservice Architecture</span>                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  Consider an e-commerce application. Instead of having a monolithic application containing all functionalities  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  such as user management, product catalog, shopping cart, order processing, and payment, the system is          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  decomposed into several microservices:                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"background-color: #272822\">                                                                                                             </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">- User Management Service (for handling user authentication, registration, and profile management)</span><span style=\"background-color: #272822\">          </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">- Product Catalog Service (manages product information, including descriptions, images, and pricing)</span><span style=\"background-color: #272822\">        </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">- Shopping Cart Service (handles shopping cart functionality, including adding/removing items, total cost </span><span style=\"background-color: #272822\">  </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">calculation, and saving user sessions)</span><span style=\"background-color: #272822\">                                                                      </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">- Order Processing Service (takes care of order creation, processing, tracking, and notifying relevant </span><span style=\"background-color: #272822\">     </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">parties)</span><span style=\"background-color: #272822\">                                                                                                    </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">- Payment Service (deals with payment integration, security, and transaction management)</span><span style=\"background-color: #272822\">                    </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"background-color: #272822\">                                                                                                             </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  Each microservice communicates through well-defined APIs, allowing them to operate independently while still   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  providing a seamless user experience.                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m───────────────────────────────────────────────────\u001b[0m\u001b[32m Answer \u001b[0m\u001b[32m────────────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                           \u001b[1;4mMicroservices Architecture\u001b[0m                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  Microservices are a distinct and organized approach to developing software applications. This architectural    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  style decomposes an application into several small, independent services. Each microservice handles a          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  specific functionality or business capability and communicates with other services through well-defined        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  interfaces (APIs).                                                                                             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                     \u001b[1mBenefits of Microservices Architecture\u001b[0m                                      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[1;33m 1 \u001b[0m\u001b[1mFlexibility\u001b[0m: Microservices allow for greater agility as each service can be developed, deployed, and        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[1;33m   \u001b[0mscaled independently.                                                                                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[1;33m 2 \u001b[0m\u001b[1mTechnology Selection\u001b[0m: Each microservice can be built using the most appropriate technology stack for its    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[1;33m   \u001b[0mspecific requirements.                                                                                      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[1;33m 3 \u001b[0m\u001b[1mIsolation\u001b[0m: Failure in one microservice does not impact the entire system, enhancing reliability and fault   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[1;33m   \u001b[0mtolerance.                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[1;33m 4 \u001b[0m\u001b[1mInnovation\u001b[0m: Teams working on different microservices can innovate quickly without being hindered by other   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[1;33m   \u001b[0mparts of the application.                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                    \u001b[1mChallenges of Microservices Architecture\u001b[0m                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[1;33m 1 \u001b[0m\u001b[1mComplexity\u001b[0m: Managing many small services can lead to a complex system, making it more difficult to          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[1;33m   \u001b[0mmaintain and troubleshoot.                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[1;33m 2 \u001b[0m\u001b[1mInter-service communication\u001b[0m: Proper communication between microservices should be well designed to          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[1;33m   \u001b[0mminimize latency and ensure data consistency.                                                               \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[1;33m 3 \u001b[0m\u001b[1mData management\u001b[0m: Sharing data between microservices may become problematic due to possible inconsistencies  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[1;33m   \u001b[0mand duplication issues.                                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[1;33m 4 \u001b[0m\u001b[1mDeployment and orchestration\u001b[0m: Automating the deployment, scaling, and monitoring of multiple microservices  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[1;33m   \u001b[0mis crucial for efficient operation.                                                                         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                          \u001b[1mIntroduction to Microservices\u001b[0m                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  Microservices were not pre-planned but evolved as a response to practical needs in software development.       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  Responding to Change is one of the main reasons behind their emergence, offering the agility and flexibility   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  required to adapt to new technologies and market demands.                                                      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  [Note: The lecture notes do not provide information about design patterns related to microservices, but I can  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  tell you that they are important when designing and managing microservices in a system.]                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[33m─────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                      \u001b[1mExample of Microservice Architecture\u001b[0m                                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  Consider an e-commerce application. Instead of having a monolithic application containing all functionalities  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  such as user management, product catalog, shopping cart, order processing, and payment, the system is          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  decomposed into several microservices:                                                                         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[48;2;39;40;34m                                                                                                             \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m- User Management Service (for handling user authentication, registration, and profile management)\u001b[0m\u001b[48;2;39;40;34m         \u001b[0m\u001b[48;2;39;40;34m \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m- Product Catalog Service (manages product information, including descriptions, images, and pricing)\u001b[0m\u001b[48;2;39;40;34m       \u001b[0m\u001b[48;2;39;40;34m \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m- Shopping Cart Service (handles shopping cart functionality, including adding/removing items, total cost \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcalculation, and saving user sessions)\u001b[0m\u001b[48;2;39;40;34m                                                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m- Order Processing Service (takes care of order creation, processing, tracking, and notifying relevant \u001b[0m\u001b[48;2;39;40;34m    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mparties)\u001b[0m\u001b[48;2;39;40;34m                                                                                                   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m- Payment Service (deals with payment integration, security, and transaction management)\u001b[0m\u001b[48;2;39;40;34m                   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[48;2;39;40;34m                                                                                                             \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  Each microservice communicates through well-defined APIs, allowing them to operate independently while still   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  providing a seamless user experience.                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Ask a question (or type /help)</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mAsk a question (or type /help)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Ask a question (or type /help)</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mAsk a question (or type /help)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Ask a question (or type /help)</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mAsk a question (or type /help)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Exiting RagChitChat<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Exiting RagChitChat\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class RagChitChat:\n",
    "    \"\"\"Main application class\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir: str = \"data\", processed_dir: str = \"processed\", db_dir: str = \"chroma_db\", model_name: str = \"mistral:7b-instruct-v0.3-q4_1\"):\n",
    "        \"\"\"Initialize the RAG chatbot\"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.processed_dir = processed_dir\n",
    "        self.db_dir = db_dir\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        # Initialize components\n",
    "        self.vector_store = ChromaVectorStore(persist_directory=db_dir)\n",
    "        self.retriever = HaystackRetriever(vector_store=self.vector_store)\n",
    "        self.llm = OllamaLLM(model=model_name)\n",
    "        \n",
    "        # Ensure data is processed\n",
    "        self._ensure_data_processed()\n",
    "    \n",
    "    def _ensure_data_processed(self) -> None:\n",
    "        \"\"\"Process lecture notes if needed\"\"\"\n",
    "        os.makedirs(self.processed_dir, exist_ok=True)\n",
    "        data_files = list(Path(self.data_dir).glob(\"**/*.*\"))\n",
    "        processed_files = list(Path(self.processed_dir).glob(\"*.txt\"))\n",
    "        \n",
    "        if not processed_files or len(data_files) > len(processed_files):\n",
    "            logger.info(\"Processing lecture notes...\")\n",
    "            self._process_lecture_notes()\n",
    "        else:\n",
    "            logger.info(\"Using existing processed lecture notes\")\n",
    "    \n",
    "    def _process_lecture_notes(self) -> None:\n",
    "        \"\"\"Process lecture notes from data directory\"\"\"\n",
    "        data_files = list(Path(self.data_dir).glob(\"**/*.*\"))\n",
    "        all_documents = []\n",
    "        \n",
    "        for file_path in data_files:\n",
    "            if file_path.suffix.lower() not in ['.pdf', '.pptx']:\n",
    "                continue\n",
    "            \n",
    "            processor = DocumentProcessorFactory.get_processor(str(file_path))\n",
    "            if processor:\n",
    "                chunks = processor.process(str(file_path))\n",
    "                output_filename = f\"{file_path.stem}.txt\"\n",
    "                processor.save_chunks(chunks, self.processed_dir, output_filename)\n",
    "                all_documents.extend(chunks)\n",
    "        \n",
    "        if all_documents:\n",
    "            logger.info(f\"Adding {len(all_documents)} document chunks to vector store\")\n",
    "            self.vector_store.add_documents(all_documents)\n",
    "            self.retriever.add_documents(all_documents)\n",
    "    \n",
    "    def generate_response(self, question: str, progress_callback: Optional[Callable] = None) -> str:\n",
    "        \"\"\"Generate response for a question\"\"\"\n",
    "        context_docs = self.retriever.hybrid_retrieve(question, top_k=5)\n",
    "        if progress_callback:\n",
    "            progress_callback(\"retrieval_complete\", {\"num_docs\": len(context_docs)})\n",
    "        return self.llm.generate(question, context_docs)\n",
    "    \n",
    "    def switch_model(self, model_name: str) -> bool:\n",
    "        \"\"\"Switch to a different Ollama model\"\"\"\n",
    "        try:\n",
    "            new_llm = OllamaLLM(model=model_name)\n",
    "            available_models = new_llm.list_models()\n",
    "            if model_name not in available_models:\n",
    "                logger.warning(f\"Model {model_name} not available in Ollama\")\n",
    "                return False\n",
    "            self.llm = new_llm\n",
    "            self.model_name = model_name\n",
    "            logger.info(f\"Successfully switched to model: {model_name}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error switching model: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def get_system_info(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get system information for the UI\"\"\"\n",
    "        vector_store_stats = self.vector_store.get_collection_stats()\n",
    "        available_models = self.llm.list_models()\n",
    "        processed_files = [f.name for f in Path(self.processed_dir).glob(\"*.txt\")]\n",
    "        return {\n",
    "            \"current_model\": self.model_name,\n",
    "            \"available_models\": available_models,\n",
    "            \"document_count\": vector_store_stats.get(\"document_count\", 0),\n",
    "            \"processed_files\": processed_files[:5] + ([\"...\"] if len(processed_files) > 5 else []),\n",
    "            \"vector_db\": \"ChromaDB\"\n",
    "        }\n",
    "    \n",
    "    def run(self) -> None:\n",
    "        \"\"\"Run the chatbot interface\"\"\"\n",
    "        system_info = self.get_system_info()\n",
    "        ui = TerminalUI(\n",
    "            generate_fn=self.generate_response,\n",
    "            system_info=system_info,\n",
    "            model_switch_fn=self.switch_model\n",
    "        )\n",
    "        ui.run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        chatbot = RagChitChat()\n",
    "        chatbot.run()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nExiting RagChitChat...\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error running RagChitChat: {str(e)}\", exc_info=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
